# Context2Task - An√°lise Cross-Validation e Detalhamento

**Data**: 2025-10-19  
**Status**: An√°lise P√≥s-Planning  
**Objetivo**: Identificar gaps, inconsist√™ncias e oportunidades de detalhamento antes do `/tasks`

---

## üìä Vis√£o Geral da An√°lise

### Documentos Analisados
- ‚úÖ `spec.md` - Especifica√ß√£o completa
- ‚úÖ `plan.md` - Plano t√©cnico de implementa√ß√£o
- ‚úÖ `system-flow-diagram.md` - 11 diagramas Mermaid
- ‚úÖ `user-flows.md` - Fluxos de usu√°rio detalhados
- ‚úÖ `priority-features-detail.md` - 9 features priorit√°rias
- ‚úÖ `multi-spec-feature.md` - Feature multi-repo
- ‚úÖ `interface-final-v2.md` - Interface redesenhada
- ‚úÖ `company-task-template.md` - Template da empresa
- ‚úÖ `openrouter-integration-notes.md` - Integra√ß√£o OpenRouter
- ‚úÖ `mcp-integration-notes.md` - Integra√ß√£o MCP

---

## üîç PARTE 1: Inconsist√™ncias Identificadas

### ‚úÖ Status: TODAS RESOLVIDAS

Todas as inconsist√™ncias foram corrigidas:
- ‚úÖ GitHub Projects vs GitHub Issues ‚Üí Corrigido em todos documentos
- ‚úÖ Tech Debt: grep vs IA ‚Üí Corrigido para an√°lise inteligente
- ‚úÖ Markdown Preview: side-by-side vs final ‚Üí Esclarecido (s√≥ no final)

---

## üéØ PARTE 2: Gaps de Informa√ß√£o Cr√≠ticos

### 1. üîê Estrat√©gia de Sanitiza√ß√£o de Dados Sens√≠veis

**Gap**: `spec.md` menciona "dados sens√≠veis", mas n√£o h√° detalhamento de QUAIS dados e COMO sanitizar.

**Recomenda√ß√£o: Criar documento detalhado**

```yaml
# sanitization-rules.yml

sensitive_patterns:
  pii:
    - type: "cpf"
      regex: '\b\d{3}\.\d{3}\.\d{3}-\d{2}\b'
      replacement: "[CPF_REDACTED]"
      severity: "critical"
    
    - type: "email"
      regex: '\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b'
      replacement: "[EMAIL_REDACTED]"
      severity: "medium"
    
    - type: "phone"
      regex: '\b\(\d{2}\)\s?\d{4,5}-\d{4}\b'
      replacement: "[PHONE_REDACTED]"
      severity: "medium"
  
  credentials:
    - type: "password"
      regex: '(?i)(senha|password|pwd)\s*[:=]\s*\S+'
      replacement: "[PASSWORD_REDACTED]"
      severity: "critical"
    
    - type: "api_key"
      regex: '(?i)(api[_-]?key|token|secret)\s*[:=]\s*["\']?([a-zA-Z0-9_-]{20,})["\']?'
      replacement: "[API_KEY_REDACTED]"
      severity: "critical"
    
    - type: "jwt"
      regex: 'eyJ[a-zA-Z0-9_-]*\.eyJ[a-zA-Z0-9_-]*\.[a-zA-Z0-9_-]*'
      replacement: "[JWT_REDACTED]"
      severity: "critical"
  
  healthcare:
    - type: "medical_diagnosis"
      regex: '(?i)(diagn√≥stico|cid-10|doen√ßa)\s*:\s*[^\\n]+'
      replacement: "[DIAGNOSIS_REDACTED]"
      severity: "critical"
    
    - type: "medication"
      regex: '(?i)(medicamento|rem√©dio|prescri√ß√£o)\s*:\s*[^\\n]+'
      replacement: "[MEDICATION_REDACTED]"
      severity: "high"

sanitization_strategy:
  before_mcp_search: true
  before_llm_prompt: true
  in_logs: true
  in_exports: false  # User wants full context in exports
  
  redaction_modes:
    development: "partial"  # Show first 3 chars
    production: "full"      # Complete redaction
  
  audit:
    log_sanitizations: true
    log_location: "logs/sanitization-audit.log"
    alert_on_critical: true
```

**Implementa√ß√£o no Backend**:
```python
# backend/utils/sanitization.py

from typing import List, Dict
import re
import yaml

class SanitizationEngine:
    def __init__(self, rules_path: str = ".context2task/sanitization-rules.yml"):
        with open(rules_path, 'r') as f:
            self.rules = yaml.safe_load(f)
        self.patterns = self._compile_patterns()
    
    def _compile_patterns(self) -> List[Dict]:
        """Compile regex patterns from rules"""
        compiled = []
        for category in self.rules['sensitive_patterns'].values():
            for rule in category:
                compiled.append({
                    'type': rule['type'],
                    'pattern': re.compile(rule['regex']),
                    'replacement': rule['replacement'],
                    'severity': rule['severity']
                })
        return compiled
    
    def sanitize_text(self, text: str, context: str = "general") -> tuple[str, List[Dict]]:
        """
        Sanitize text and return cleaned text + audit log
        
        Args:
            text: Text to sanitize
            context: Context of sanitization (mcp_search, llm_prompt, logs, etc.)
        
        Returns:
            (sanitized_text, audit_entries)
        """
        audit_entries = []
        result = text
        
        for pattern_info in self.patterns:
            matches = pattern_info['pattern'].findall(result)
            if matches:
                result = pattern_info['pattern'].sub(
                    pattern_info['replacement'], 
                    result
                )
                
                audit_entries.append({
                    'type': pattern_info['type'],
                    'count': len(matches),
                    'severity': pattern_info['severity'],
                    'context': context
                })
        
        return result, audit_entries
    
    def sanitize_context_batch(self, contexts: List[Dict]) -> List[Dict]:
        """Sanitize batch of MCP search results"""
        sanitized = []
        total_audit = []
        
        for ctx in contexts:
            clean_content, audit = self.sanitize_text(
                ctx['content'], 
                context='mcp_search'
            )
            
            sanitized.append({
                **ctx,
                'content': clean_content,
                'sanitized': len(audit) > 0
            })
            
            total_audit.extend(audit)
        
        # Log critical sanitizations
        critical = [a for a in total_audit if a['severity'] == 'critical']
        if critical:
            logger.warning(
                "critical_data_sanitized",
                count=len(critical),
                types=[a['type'] for a in critical]
            )
        
        return sanitized

# Usage example
sanitizer = SanitizationEngine()

# Before sending to MCP
contexts = await mcp_client.search_code(repo, query, limit=20)
clean_contexts = sanitizer.sanitize_context_batch(contexts)

# Before sending to LLM
prompt_text, audit = sanitizer.sanitize_text(
    build_prompt(clean_contexts),
    context='llm_prompt'
)
```

---

### 2. üìù Prompts Especializados para IA

**Gap**: Documentos mencionam "prompts especializados" mas n√£o detalham a estrutura exata.

**Recomenda√ß√£o: Criar biblioteca de prompts**

```python
# backend/prompts/templates.py

from typing import Dict, List
from enum import Enum

class UserProfile(Enum):
    TECHNICAL = "technical"
    NON_TECHNICAL = "non_technical"

class PromptLibrary:
    """Centralized prompt templates for all AI interactions"""
    
    @staticmethod
    def system_prompt(profile: UserProfile) -> str:
        """Base system prompt based on user profile"""
        
        base = """Voc√™ √© um assistente especializado em criar especifica√ß√µes t√©cnicas de features.
Voc√™ tem acesso ao c√≥digo-fonte do projeto atrav√©s de contexto fornecido.

REGRAS FUNDAMENTAIS:
1. Sempre baseie suas respostas no contexto de c√≥digo fornecido
2. Cite arquivos e linhas espec√≠ficas quando relevante
3. Apresente m√∫ltiplas op√ß√µes (tradeoffs) quando apropriado
4. Seja espec√≠fico e acion√°vel
5. Mantenha consist√™ncia com a arquitetura existente
"""
        
        if profile == UserProfile.NON_TECHNICAL:
            return base + """
PERFIL DO USU√ÅRIO: N√ÉO-T√âCNICO (Product Owner)

ADAPTA√á√ïES:
- Use linguagem simples, evite jarg√µes t√©cnicos
- Explique conceitos t√©cnicos com analogias
- Foque em benef√≠cios de neg√≥cio, n√£o implementa√ß√£o
- Estimativas em dias/semanas, n√£o story points
- Esconda detalhes t√©cnicos (mas ofere√ßa "Mostrar detalhes")
- Use emojis para facilitar compreens√£o üí°
- Sempre explique siglas na primeira men√ß√£o

EXEMPLO BOM:
"Vou usar Firebase (um servi√ßo do Google) para enviar notifica√ß√µes.
Vantagem: R√°pido de implementar (2 dias)
Custo: ~$50/m√™s"

EXEMPLO RUIM:
"Implementar FCM SDK com async workers e exponential backoff"
"""
        else:  # TECHNICAL
            return base + """
PERFIL DO USU√ÅRIO: T√âCNICO (Developer/Tech Lead)

ADAPTA√á√ïES:
- Use terminologia t√©cnica precisa
- Detalhe arquitetura e padr√µes de design
- Apresente m√©tricas de performance
- Analise complexidade e tradeoffs t√©cnicos
- Mostre trechos de c√≥digo relevantes
- Sugira otimiza√ß√µes e refatora√ß√µes
- Cite RFCs, docs e best practices

EXEMPLO BOM:
"Implementar FCM via firebase-admin SDK (Python):
- Async/await com asyncio.gather() para batch sends
- Retry com exponential backoff (2^n segundos)
- Rate limiting: 500 req/s (quota do FCM)
- Lat√™ncia esperada: 200-500ms P95"

EXEMPLO RUIM:
"Vamos usar o Firebase para notifica√ß√µes"
"""
    
    @staticmethod
    def initial_analysis_prompt(
        feature_description: str,
        code_context: List[Dict],
        profile: UserProfile
    ) -> str:
        """Prompt for initial feature analysis"""
        
        context_str = "\n\n".join([
            f"Arquivo: {ctx['file']} (linhas {ctx['start_line']}-{ctx['end_line']})\n"
            f"Relev√¢ncia: {ctx['score']:.0%}\n"
            f"C√≥digo:\n{ctx['content']}"
            for ctx in code_context[:5]  # Top 5 most relevant
        ])
        
        return f"""Analise a seguinte feature solicitada pelo usu√°rio:

FEATURE SOLICITADA:
{feature_description}

CONTEXTO DO C√ìDIGO ATUAL:
{context_str}

TAREFAS:
1. Identifique arquivos e m√≥dulos que ser√£o impactados
2. Liste funcionalidades existentes que podem ser reutilizadas
3. {"Apresente 2-3 op√ß√µes de implementa√ß√£o com tradeoffs" if profile == UserProfile.TECHNICAL else "Sugira a melhor forma de implementar (linguagem simples)"}
4. Identifique poss√≠veis desafios t√©cnicos
5. {"Estime complexidade (pontos de story)" if profile == UserProfile.TECHNICAL else "Estime tempo de implementa√ß√£o em dias"}

FORMATO DA RESPOSTA:
Use markdown estruturado, com se√ß√µes claras e emojis.
"""
    
    @staticmethod
    def tech_debt_analysis_prompt(
        feature_title: str,
        code_context: List[Dict],
        tech_stack: Dict[str, str]
    ) -> str:
        """Specialized prompt for tech debt detection"""
        
        context_str = "\n\n".join([
            f"=== {ctx['file']} ===\n{ctx['content']}"
            for ctx in code_context[:15]  # More context for analysis
        ])
        
        return f"""Voc√™ √© um arquiteto de software s√™nior especializado em an√°lise de qualidade de c√≥digo.

CONTEXTO:
Estamos implementando a feature: "{feature_title}"

STACK TECNOL√ìGICA:
{yaml.dump(tech_stack, default_flow_style=False)}

C√ìDIGO RELACIONADO √Ä FEATURE:
{context_str}

TAREFA: An√°lise profunda de Tech Debt

Analise o c√≥digo acima e identifique problemas nas seguintes categorias:

1. **Code Smells**:
   - M√©todos muito longos (> 20 linhas)
   - Classes com muitas responsabilidades (> 300 LOC)
   - Complexidade ciclom√°tica alta (> 10)
   - Par√¢metros demais em fun√ß√µes (> 5)

2. **Duplica√ß√£o de C√≥digo**:
   - Blocos de c√≥digo similares (> 80% de similaridade)
   - L√≥gica repetida que poderia ser abstra√≠da

3. **Anti-Patterns**:
   - Singleton com estado mut√°vel
   - Magic numbers/strings sem constantes
   - God objects
   - Tight coupling entre m√≥dulos

4. **Performance Issues**:
   - N+1 queries
   - Loops desnecess√°rios
   - Aloca√ß√µes de mem√≥ria excessivas
   - I/O bloqueante em c√≥digo async

5. **Acoplamento**:
   - Depend√™ncias circulares
   - Acoplamento tight entre camadas
   - Falta de invers√£o de depend√™ncias

6. **Testabilidade**:
   - C√≥digo n√£o test√°vel (hard dependencies)
   - Falta de interfaces/abstra√ß√µes
   - L√≥gica complexa sem separa√ß√£o

7. **Viola√ß√µes de Best Practices** (espec√≠fico para {tech_stack}):
   - Naming conventions
   - Estrutura de pastas
   - Padr√µes do framework/linguagem

FORMATO DE RESPOSTA (JSON ESTRUTURADO):

```json
{{
  "tech_debt": [
    {{
      "severity": "critical|medium|low",
      "category": "code_smell|duplication|anti_pattern|performance|coupling|testability|best_practice",
      "file": "path/to/file.py",
      "line": 123,
      "issue": "Descri√ß√£o clara e espec√≠fica do problema",
      "suggestion": "Sugest√£o concreta de refatora√ß√£o com exemplo",
      "effort_hours": 2.0,
      "priority_reason": "Por que isso √© cr√≠tico/m√©dio/baixo"
    }}
  ],
  "summary": {{
    "total_issues": 8,
    "critical": 3,
    "medium": 3,
    "low": 2,
    "total_effort_hours": 12.5,
    "recommendation": "Texto resumindo se deve refatorar antes da feature"
  }}
}}
```

IMPORTANTE:
- Seja espec√≠fico (cite linhas exatas)
- D√™ exemplos de c√≥digo na sugest√£o
- Estime esfor√ßo realisticamente
- Priorize por impacto na feature atual
"""
    
    @staticmethod
    def security_analysis_prompt(
        feature_description: str,
        code_context: List[Dict],
        company_rules: Dict
    ) -> str:
        """Specialized prompt for security analysis"""
        
        return f"""Voc√™ √© um especialista em seguran√ßa de aplica√ß√µes e compliance.

FEATURE A ANALISAR:
{feature_description}

C√ìDIGO ENVOLVIDO:
{yaml.dump([c['file'] for c in code_context], default_flow_style=False)}

REGRAS DE COMPLIANCE DA EMPRESA:
{yaml.dump(company_rules, default_flow_style=False)}

TAREFA: An√°lise de Seguran√ßa

Analise a feature sob as seguintes perspectivas:

1. **LGPD & Dados Pessoais**:
   - A feature manipula dados pessoais (CPF, email, telefone)?
   - H√° dados sens√≠veis (sa√∫de, ra√ßa, religi√£o)?
   - Consentimento expl√≠cito √© necess√°rio?
   - Prazo de reten√ß√£o est√° definido?
   - Pseudonimiza√ß√£o/anonimiza√ß√£o necess√°ria?

2. **OWASP Top 10**:
   - A01: Broken Access Control
   - A02: Cryptographic Failures
   - A03: Injection (SQL, XSS, etc.)
   - A04: Insecure Design
   - A05: Security Misconfiguration
   - A07: Auth Failures
   - A08: Software and Data Integrity Failures

3. **API Security** (se aplic√°vel):
   - Rate limiting necess√°rio?
   - Autentica√ß√£o JWT correta?
   - Valida√ß√£o de inputs?
   - CORS configurado?
   - HTTPS enforced?

4. **Crit√©rios Espec√≠ficos da Empresa**:
   Verifique conformidade com regras fornecidas acima

FORMATO DE RESPOSTA (JSON):

```json
{{
  "security_checks": [
    {{
      "category": "lgpd|owasp|api|company_specific",
      "check_name": "Nome do check",
      "status": "pass|fail|warning|not_applicable",
      "severity": "critical|high|medium|low",
      "finding": "Descri√ß√£o do problema encontrado (se fail/warning)",
      "recommendation": "A√ß√£o necess√°ria para corrigir",
      "compliance_impact": "Impacto no compliance (legal, reputacional, etc.)"
    }}
  ],
  "summary": {{
    "total_checks": 15,
    "passed": 10,
    "failed": 3,
    "warnings": 2,
    "critical_issues": 1,
    "overall_status": "pass|fail|warning"
  }},
  "recommendations": [
    "Lista de a√ß√µes priorit√°rias para resolver problemas cr√≠ticos"
  ]
}}
```
"""
    
    @staticmethod
    def multi_spec_detection_prompt(
        feature_description: str,
        repositories: List[str],
        impact_analysis: Dict[str, float]
    ) -> str:
        """Prompt to detect if feature needs multi-spec split"""
        
        return f"""Analise se a feature abaixo deve ser dividida em m√∫ltiplas especifica√ß√µes.

FEATURE:
{feature_description}

REPOSIT√ìRIOS ANALISADOS:
{yaml.dump(impact_analysis, default_flow_style=False)}

CRIT√âRIOS PARA SPLIT:

1. **Impacto em M√∫ltiplos Repos** (threshold: 70%):
   - Se 2+ repos t√™m score > 0.7, considerar split

2. **Natureza das Mudan√ßas**:
   - Mudan√ßas independentes? ‚Üí Split
   - Mudan√ßas fortemente acopladas? ‚Üí Spec √∫nica

3. **Times Diferentes**:
   - Backend team ‚â† Frontend team ‚Üí Split
   - Mesmo time ‚Üí Spec √∫nica pode ser OK

4. **Paraleliza√ß√£o**:
   - Trabalho pode ser feito em paralelo? ‚Üí Split
   - Precisa sequencial? ‚Üí Avaliar caso a caso

RESPONDA EM JSON:

```json
{{
  "should_split": true/false,
  "confidence": 0.95,
  "reasoning": "Explica√ß√£o da decis√£o",
  "recommended_split": {{
    "backend-api": {{
      "focus": "Lista do que vai neste spec",
      "estimated_effort": "3-5 dias",
      "priority": "P0 - deve ser feito primeiro",
      "dependencies": []
    }},
    "frontend-web": {{
      "focus": "Lista do que vai neste spec",
      "estimated_effort": "2-3 dias",
      "priority": "P1 - depende do backend",
      "dependencies": ["backend-api"]
    }}
  }},
  "linking_strategy": "Como as specs devem ser linkadas"
}}
```
"""
    
    @staticmethod
    def diagram_generation_prompt(
        feature_description: str,
        architecture_context: Dict,
        diagram_type: str
    ) -> str:
        """Prompt to generate Mermaid diagrams"""
        
        diagrams = {
            "architecture": "Diagrama de arquitetura mostrando componentes, APIs, databases",
            "flow": "Diagrama de fluxo de dados mostrando como dados se movem",
            "sequence": "Diagrama de sequ√™ncia mostrando intera√ß√µes temporais",
            "er": "Diagrama entidade-relacionamento mostrando models e rela√ß√µes"
        }
        
        return f"""Gere um diagrama Mermaid para documentar a feature.

FEATURE:
{feature_description}

TIPO DE DIAGRAMA: {diagram_type}
Objetivo: {diagrams.get(diagram_type, 'Diagrama gen√©rico')}

CONTEXTO DE ARQUITETURA:
{yaml.dump(architecture_context, default_flow_style=False)}

INSTRU√á√ïES:

1. Crie diagrama Mermaid v√°lido (sintaxe correta)
2. Use cores e estilos para clareza
3. Adicione labels descritivos
4. Mantenha simplicidade (n√£o complexo demais)
5. Foque nos componentes relacionados √† feature

FORMATO DE RESPOSTA:

```json
{{
  "mermaid_code": "graph TB\\n  A[Component]...",
  "explanation": "Explica√ß√£o do diagrama em portugu√™s",
  "key_components": [
    "Lista dos componentes principais mostrados"
  ],
  "data_flows": [
    "Descri√ß√£o dos fluxos de dados importantes"
  ]
}}
```

EXEMPLO (para refer√™ncia de estilo):

```mermaid
graph TB
    subgraph "Frontend"
        UI[React App]
        Notif[Notification Component]
    end
    
    subgraph "Backend"
        API[FastAPI]
        Service[Notification Service]
        Queue[Redis Queue]
    end
    
    UI -->|HTTP POST| API
    API -->|Enqueue| Queue
    Service -->|Poll| Queue
    Service -->|Send| FCM[Firebase]
    
    style UI fill:#61dafb
    style API fill:#009688
    style FCM fill:#ff6b6b
```
"""
```

---

### 3. üß™ Casos de Borda e Edge Cases

**Gap**: Poucos casos de borda documentados de forma estruturada.

**Recomenda√ß√£o: Criar cat√°logo de edge cases**

```yaml
# edge-cases-catalog.yml

session_management:
  - case: "Usu√°rio fecha navegador durante conversa"
    expected_behavior: "Sess√£o expira ap√≥s 30min. Dados perdidos (V1 in-memory)"
    mitigation: "Auto-save a cada mensagem (localStorage como backup)"
    priority: "high"
  
  - case: "M√∫ltiplas abas abertas com mesma sess√£o"
    expected_behavior: "Cada aba mant√©m sess√£o independente"
    mitigation: "Session ID no localStorage compartilhado"
    priority: "medium"
  
  - case: "Sess√£o expira durante an√°lise de tech debt"
    expected_behavior: "An√°lise √© perdida"
    mitigation: "Background tasks com timeout + retry"
    priority: "high"

mcp_integration:
  - case: "MCP server est√° offline"
    expected_behavior: "Erro gracioso: 'Reposit√≥rio n√£o dispon√≠vel'"
    fallback: "Modo degradado: continua sem contexto de c√≥digo"
    priority: "critical"
  
  - case: "Reposit√≥rio muito grande (> 10GB)"
    expected_behavior: "Indexa√ß√£o parcial ou timeout"
    mitigation: "Indexar por partes + mostrar progresso + permitir cancelar"
    priority: "high"
  
  - case: "Busca retorna 0 resultados"
    expected_behavior: "IA avisa: 'N√£o encontrei c√≥digo relacionado'"
    fallback: "Sugerir termos alternativos ou continuar sem contexto"
    priority: "medium"
  
  - case: "Token limit exceeded no contexto"
    expected_behavior: "Selecionar top N resultados mais relevantes"
    mitigation: "Implementar ranking + trunca√ß√£o inteligente"
    priority: "high"

llm_integration:
  - case: "OpenRouter rate limit"
    expected_behavior: "Erro 429 ‚Üí retry com backoff exponencial"
    mitigation: "Queue de requisi√ß√µes + mostrar 'Aguardando...'"
    priority: "critical"
  
  - case: "LLM responde em formato inv√°lido"
    expected_behavior: "Parser falha ‚Üí retry com prompt ajustado"
    mitigation: "Valida√ß√£o + fallback para resposta parcial"
    priority: "high"
  
  - case: "LLM timeout (> 30s)"
    expected_behavior: "Cancela requisi√ß√£o ‚Üí tenta modelo fallback"
    mitigation: "Streaming + timeout configur√°vel"
    priority: "high"
  
  - case: "Resposta do LLM cont√©m c√≥digo malicioso"
    expected_behavior: "Sanitiza√ß√£o antes de mostrar ao usu√°rio"
    mitigation: "Code injection detection + sandboxing"
    priority: "critical"

user_input:
  - case: "Feature description muito vaga ('melhore o sistema')"
    expected_behavior: "IA faz 3-5 perguntas de esclarecimento"
    mitigation: "Template de perguntas obrigat√≥rias"
    priority: "medium"
  
  - case: "Usu√°rio envia 10k caracteres de texto"
    expected_behavior: "Trunca para 10k + avisa"
    mitigation: "Valida√ß√£o no frontend + backend"
    priority: "low"
  
  - case: "Input cont√©m SQL injection attempt"
    expected_behavior: "Sanitiza√ß√£o autom√°tica + log"
    mitigation: "Input validation + WAF-like rules"
    priority: "critical"
  
  - case: "Voice input com ru√≠do excessivo"
    expected_behavior: "Transcri√ß√£o ruim ‚Üí avisar usu√°rio"
    mitigation: "Audio quality check antes de enviar"
    priority: "medium"

multi_spec:
  - case: "Split autom√°tico sugere 5+ reposit√≥rios"
    expected_behavior: "Avisar: 'Muitos repos, revise a sele√ß√£o'"
    mitigation: "Limite m√°ximo de 4 specs + avisar sobre complexidade"
    priority: "medium"
  
  - case: "Usu√°rio n√£o-t√©cnico deseja editar split sugerido"
    expected_behavior: "Permitir selecionar manualmente quais repos incluir"
    mitigation: "UI simples de checkbox"
    priority: "low"
  
  - case: "Depend√™ncias circulares entre specs"
    expected_behavior: "Detectar e avisar: 'Ordem de implementa√ß√£o indefinida'"
    mitigation: "An√°lise de grafo de depend√™ncias"
    priority: "medium"

export:
  - case: "Documento gerado est√° incompleto (< 50% se√ß√µes)"
    expected_behavior: "Avisar antes de exportar: 'Spec incompleta'"
    mitigation: "Checklist de valida√ß√£o + op√ß√£o de continuar"
    priority: "medium"
  
  - case: "GitHub API est√° offline"
    expected_behavior: "Erro gracioso + oferecer download local"
    mitigation: "Retry + fallback para download"
    priority: "high"
  
  - case: "Export de 3 specs leva > 30s"
    expected_behavior: "Mostrar progresso (1/3, 2/3, 3/3)"
    mitigation: "Background task + WebSocket updates"
    priority: "low"

security:
  - case: "Sanitiza√ß√£o falha (regex bug)"
    expected_behavior: "Log erro + bloqueia envio ao LLM"
    mitigation: "Fallback: reda√ß√£o completa se sanitiza√ß√£o falhar"
    priority: "critical"
  
  - case: "Usu√°rio tenta acessar sess√£o de outro"
    expected_behavior: "401 Unauthorized"
    mitigation: "Session validation em toda requisi√ß√£o"
    priority: "critical"

performance:
  - case: "An√°lise de tech debt leva > 60s"
    expected_behavior: "Timeout + resultado parcial"
    mitigation: "Streaming de resultados + cancelamento"
    priority: "medium"
  
  - case: "100 usu√°rios simult√¢neos"
    expected_behavior: "Rate limiting por IP/session"
    mitigation: "Load balancer + sess√µes distribu√≠das (V2 com Redis)"
    priority: "low (V1 expectativa: < 10 usu√°rios simult√¢neos)"
```

---

## üéØ PARTE 3: Detalhamentos Adicionais Recomendados

### 1. üìä M√©tricas e KPIs Detalhados

**Recomenda√ß√£o: Dashboard de observabilidade**

```python
# backend/monitoring/metrics.py

from dataclasses import dataclass
from typing import Dict, List
from datetime import datetime
import structlog

logger = structlog.get_logger()

@dataclass
class SessionMetrics:
    """M√©tricas por sess√£o"""
    session_id: str
    user_profile: str
    started_at: datetime
    ended_at: datetime
    
    # Engagement
    messages_sent: int
    ai_responses: int
    conversation_duration_seconds: int
    
    # Context
    mcp_searches_count: int
    mcp_results_found: int
    mcp_average_relevance: float
    repositories_used: List[str]
    
    # Output
    spec_generated: bool
    spec_completeness_percent: int
    export_format: str
    multi_spec: bool
    
    # Features Used
    voice_input_used: bool
    tech_debt_analysis: bool
    security_check: bool
    diagram_generated: bool
    review_mode: bool
    
    # Performance
    total_llm_tokens: int
    llm_cost_usd: float
    mcp_latency_avg_ms: float
    llm_latency_avg_ms: float

@dataclass
class SystemMetrics:
    """M√©tricas do sistema"""
    timestamp: datetime
    
    # Usage
    active_sessions: int
    total_sessions_today: int
    specs_generated_today: int
    
    # Performance
    avg_response_time_ms: float
    p95_response_time_ms: float
    p99_response_time_ms: float
    
    # External Services
    mcp_uptime_percent: float
    openrouter_uptime_percent: float
    mcp_error_rate: float
    llm_error_rate: float
    
    # Resources
    memory_usage_mb: float
    cpu_usage_percent: float
    active_mcp_connections: int
    
    # Costs
    total_llm_cost_today_usd: float
    cost_per_spec_avg_usd: float

class MetricsCollector:
    """Coletor centralizado de m√©tricas"""
    
    def __init__(self):
        self.session_metrics: Dict[str, SessionMetrics] = {}
    
    def track_session_start(self, session_id: str, profile: str):
        """Rastreia in√≠cio de sess√£o"""
        self.session_metrics[session_id] = SessionMetrics(
            session_id=session_id,
            user_profile=profile,
            started_at=datetime.now(),
            ended_at=None,
            messages_sent=0,
            # ... inicializar todos campos
        )
        
        logger.info(
            "session_started",
            session_id=session_id,
            profile=profile
        )
    
    def track_message(self, session_id: str, is_user: bool):
        """Rastreia mensagem enviada"""
        if session_id in self.session_metrics:
            if is_user:
                self.session_metrics[session_id].messages_sent += 1
            else:
                self.session_metrics[session_id].ai_responses += 1
    
    def track_mcp_search(
        self, 
        session_id: str, 
        results_count: int, 
        avg_relevance: float,
        latency_ms: float
    ):
        """Rastreia busca no MCP"""
        if session_id in self.session_metrics:
            metrics = self.session_metrics[session_id]
            metrics.mcp_searches_count += 1
            metrics.mcp_results_found += results_count
            # Update rolling average
            metrics.mcp_average_relevance = (
                (metrics.mcp_average_relevance * (metrics.mcp_searches_count - 1) +
                 avg_relevance) / metrics.mcp_searches_count
            )
        
        logger.info(
            "mcp_search_completed",
            session_id=session_id,
            results_count=results_count,
            latency_ms=latency_ms
        )
    
    def track_llm_call(
        self,
        session_id: str,
        tokens_used: int,
        cost_usd: float,
        latency_ms: float
    ):
        """Rastreia chamada ao LLM"""
        if session_id in self.session_metrics:
            metrics = self.session_metrics[session_id]
            metrics.total_llm_tokens += tokens_used
            metrics.llm_cost_usd += cost_usd
        
        logger.info(
            "llm_call_completed",
            session_id=session_id,
            tokens=tokens_used,
            cost_usd=cost_usd,
            latency_ms=latency_ms
        )
    
    def get_kpis(self) -> Dict:
        """Calcula KPIs agregados"""
        completed_sessions = [
            s for s in self.session_metrics.values()
            if s.spec_generated
        ]
        
        if not completed_sessions:
            return {}
        
        return {
            "success_rate": len(completed_sessions) / len(self.session_metrics),
            "avg_conversation_duration_min": sum(
                s.conversation_duration_seconds for s in completed_sessions
            ) / len(completed_sessions) / 60,
            "avg_messages_per_session": sum(
                s.messages_sent for s in completed_sessions
            ) / len(completed_sessions),
            "avg_spec_completeness": sum(
                s.spec_completeness_percent for s in completed_sessions
            ) / len(completed_sessions),
            "voice_adoption_rate": sum(
                1 for s in completed_sessions if s.voice_input_used
            ) / len(completed_sessions),
            "tech_debt_usage_rate": sum(
                1 for s in completed_sessions if s.tech_debt_analysis
            ) / len(completed_sessions),
            "multi_spec_rate": sum(
                1 for s in completed_sessions if s.multi_spec
            ) / len(completed_sessions),
            "avg_cost_per_spec_usd": sum(
                s.llm_cost_usd for s in completed_sessions
            ) / len(completed_sessions),
            "avg_mcp_latency_ms": sum(
                s.mcp_latency_avg_ms for s in completed_sessions
            ) / len(completed_sessions),
        }

# Usage
metrics = MetricsCollector()

# Em cada endpoint
metrics.track_session_start(session_id, profile)
metrics.track_message(session_id, is_user=True)
# ...

# Dashboard endpoint
@app.get("/api/admin/metrics/kpis")
async def get_kpis():
    return metrics.get_kpis()
```

---

### 2. üîÑ M√°quina de Estados para Sess√£o

**Recomenda√ß√£o: Formalizar estados da sess√£o**

```python
# backend/models/session_state.py

from enum import Enum
from typing import Optional
from datetime import datetime

class SessionState(Enum):
    """Estados poss√≠veis de uma sess√£o"""
    INITIALIZING = "initializing"
    REPO_SELECTION = "repo_selection"
    PROFILE_SELECTION = "profile_selection"
    INITIAL_INPUT = "initial_input"
    MCP_SEARCHING = "mcp_searching"
    CONVERSATION = "conversation"
    MULTI_SPEC_DETECTED = "multi_spec_detected"
    MULTI_SPEC_CONVERSATION = "multi_spec_conversation"
    SPEC_GENERATION = "spec_generation"
    OPTIONAL_ANALYSIS = "optional_analysis"
    TECH_DEBT_ANALYZING = "tech_debt_analyzing"
    SECURITY_ANALYZING = "security_analyzing"
    DIAGRAM_GENERATING = "diagram_generating"
    READY_FOR_EXPORT = "ready_for_export"
    EXPORTING = "exporting"
    REVIEW_MODE = "review_mode"
    COMPLETED = "completed"
    ERROR = "error"
    EXPIRED = "expired"

class StateTransition:
    """Regras de transi√ß√£o entre estados"""
    
    ALLOWED_TRANSITIONS = {
        SessionState.INITIALIZING: [
            SessionState.REPO_SELECTION,
            SessionState.ERROR
        ],
        SessionState.REPO_SELECTION: [
            SessionState.PROFILE_SELECTION,
            SessionState.ERROR
        ],
        SessionState.PROFILE_SELECTION: [
            SessionState.INITIAL_INPUT,
            SessionState.ERROR
        ],
        SessionState.INITIAL_INPUT: [
            SessionState.MCP_SEARCHING,
            SessionState.ERROR
        ],
        SessionState.MCP_SEARCHING: [
            SessionState.CONVERSATION,
            SessionState.MULTI_SPEC_DETECTED,
            SessionState.ERROR
        ],
        SessionState.CONVERSATION: [
            SessionState.CONVERSATION,  # Loop
            SessionState.MCP_SEARCHING,  # Nova busca
            SessionState.SPEC_GENERATION,
            SessionState.ERROR
        ],
        SessionState.MULTI_SPEC_DETECTED: [
            SessionState.MULTI_SPEC_CONVERSATION,
            SessionState.CONVERSATION,  # Se usu√°rio rejeitar split
            SessionState.ERROR
        ],
        SessionState.MULTI_SPEC_CONVERSATION: [
            SessionState.MULTI_SPEC_CONVERSATION,  # Loop
            SessionState.SPEC_GENERATION,
            SessionState.ERROR
        ],
        SessionState.SPEC_GENERATION: [
            SessionState.OPTIONAL_ANALYSIS,
            SessionState.READY_FOR_EXPORT,
            SessionState.ERROR
        ],
        SessionState.OPTIONAL_ANALYSIS: [
            SessionState.TECH_DEBT_ANALYZING,
            SessionState.SECURITY_ANALYZING,
            SessionState.DIAGRAM_GENERATING,
            SessionState.READY_FOR_EXPORT,  # Pular an√°lises
            SessionState.ERROR
        ],
        SessionState.TECH_DEBT_ANALYZING: [
            SessionState.OPTIONAL_ANALYSIS,  # Voltar para escolher outras
            SessionState.READY_FOR_EXPORT,
            SessionState.ERROR
        ],
        SessionState.SECURITY_ANALYZING: [
            SessionState.OPTIONAL_ANALYSIS,
            SessionState.READY_FOR_EXPORT,
            SessionState.ERROR
        ],
        SessionState.DIAGRAM_GENERATING: [
            SessionState.OPTIONAL_ANALYSIS,
            SessionState.READY_FOR_EXPORT,
            SessionState.ERROR
        ],
        SessionState.READY_FOR_EXPORT: [
            SessionState.EXPORTING,
            SessionState.REVIEW_MODE,
            SessionState.CONVERSATION,  # Voltar para editar
            SessionState.ERROR
        ],
        SessionState.EXPORTING: [
            SessionState.COMPLETED,
            SessionState.ERROR
        ],
        SessionState.REVIEW_MODE: [
            SessionState.REVIEW_MODE,  # Loop de reviews
            SessionState.READY_FOR_EXPORT,  # Aprovado
            SessionState.CONVERSATION,  # Rejeitado, volta para edi√ß√£o
            SessionState.ERROR
        ],
        SessionState.COMPLETED: [],  # Estado final
        SessionState.ERROR: [
            # Pode tentar recuperar para alguns estados
            SessionState.INITIAL_INPUT,
            SessionState.CONVERSATION
        ],
        SessionState.EXPIRED: []  # Estado final
    }
    
    @classmethod
    def can_transition(
        cls, 
        from_state: SessionState, 
        to_state: SessionState
    ) -> bool:
        """Valida se transi√ß√£o √© permitida"""
        return to_state in cls.ALLOWED_TRANSITIONS.get(from_state, [])
    
    @classmethod
    def validate_transition(
        cls,
        from_state: SessionState,
        to_state: SessionState
    ) -> None:
        """Valida transi√ß√£o ou levanta exce√ß√£o"""
        if not cls.can_transition(from_state, to_state):
            raise InvalidStateTransitionError(
                f"Cannot transition from {from_state.value} "
                f"to {to_state.value}"
            )

class SessionStateMachine:
    """Gerencia estado da sess√£o"""
    
    def __init__(self, session_id: str):
        self.session_id = session_id
        self.current_state = SessionState.INITIALIZING
        self.state_history: List[tuple[SessionState, datetime]] = [
            (SessionState.INITIALIZING, datetime.now())
        ]
    
    def transition_to(self, new_state: SessionState) -> None:
        """Transiciona para novo estado"""
        StateTransition.validate_transition(self.current_state, new_state)
        
        self.current_state = new_state
        self.state_history.append((new_state, datetime.now()))
        
        logger.info(
            "state_transition",
            session_id=self.session_id,
            from_state=self.current_state.value,
            to_state=new_state.value
        )
    
    def is_in_state(self, *states: SessionState) -> bool:
        """Verifica se est√° em algum dos estados"""
        return self.current_state in states
    
    def can_export(self) -> bool:
        """Verifica se pode exportar"""
        return self.is_in_state(
            SessionState.READY_FOR_EXPORT,
            SessionState.REVIEW_MODE
        )
    
    def get_available_actions(self) -> List[str]:
        """Retorna a√ß√µes dispon√≠veis no estado atual"""
        actions_map = {
            SessionState.INITIAL_INPUT: ["send_message", "use_voice", "select_template"],
            SessionState.CONVERSATION: ["send_message", "finish_spec", "search_more"],
            SessionState.READY_FOR_EXPORT: ["export", "analyze_tech_debt", "security_check", "generate_diagram"],
            # ... mapear todos estados
        }
        return actions_map.get(self.current_state, [])
```

---

### 3. üß™ Suite de Testes Automatizados

**Recomenda√ß√£o: Estrat√©gia de testes completa**

```python
# tests/integration/test_full_flow.py

import pytest
from fastapi.testclient import TestClient
from backend.main import app

class TestFullSpecCreationFlow:
    """Testes end-to-end do fluxo completo"""
    
    @pytest.fixture
    def client(self):
        return TestClient(app)
    
    @pytest.fixture
    def mock_mcp(self, mocker):
        """Mock do MCP client"""
        return mocker.patch('backend.services.mcp.MCPClient')
    
    @pytest.fixture
    def mock_llm(self, mocker):
        """Mock do OpenRouter"""
        return mocker.patch('backend.services.llm.LLMService')
    
    def test_technical_user_single_repo_spec(self, client, mock_mcp, mock_llm):
        """
        Cen√°rio: Usu√°rio t√©cnico cria spec para 1 reposit√≥rio
        Validar: Todo o fluxo at√© export de markdown
        """
        
        # 1. Criar sess√£o
        response = client.post("/api/sessions", json={
            "user_profile": "technical",
            "selected_repositories": ["/test/backend-api"]
        })
        assert response.status_code == 201
        session_id = response.json()["session_id"]
        
        # 2. Enviar mensagem inicial
        mock_mcp.return_value.search_code.return_value = [
            {
                "file": "backend/cache.py",
                "start_line": 10,
                "end_line": 30,
                "content": "def get_cached()...",
                "score": 0.95
            }
        ]
        
        mock_llm.return_value.chat.return_value = {
            "content": "Entendi! Voc√™ quer implementar Redis cache...",
            "spec_updates": {
                "description": "Implementar cache Redis..."
            }
        }
        
        response = client.post("/api/conversations/message", json={
            "session_id": session_id,
            "message": "Adicionar Redis cache no SIGTAP"
        })
        
        assert response.status_code == 200
        assert "Redis" in response.json()["assistant_reply"]
        
        # 3. Continuar conversa (2-3 mensagens)
        # ... simular conversa completa
        
        # 4. Gerar spec final
        response = client.post("/api/spec/generate", json={
            "session_id": session_id
        })
        assert response.status_code == 200
        
        # 5. Analisar tech debt
        mock_llm.return_value.analyze_tech_debt.return_value = {
            "total_issues": 5,
            "critical": [
                {
                    "file": "backend/cache.py",
                    "issue": "Long method"
                }
            ]
        }
        
        response = client.post("/api/analysis/tech-debt", json={
            "session_id": session_id
        })
        assert response.status_code == 200
        assert response.json()["total_items"] == 5
        
        # 6. Exportar markdown
        response = client.post("/api/export", json={
            "session_id": session_id,
            "format": "markdown"
        })
        
        assert response.status_code == 200
        markdown = response.json()["specs"]["backend-api"]
        
        # Validar estrutura do markdown
        assert "## üìå Descri√ß√£o" in markdown
        assert "## üë§ User Story" in markdown
        assert "## ‚öôÔ∏è Detalhes T√©cnicos" in markdown
        assert "Redis" in markdown
    
    def test_non_technical_user_multi_repo_auto_split(
        self, 
        client, 
        mock_mcp, 
        mock_llm
    ):
        """
        Cen√°rio: Usu√°rio n√£o-t√©cnico descreve feature que impacta m√∫ltiplos repos
        Validar: Sistema detecta automaticamente e cria m√∫ltiplas specs
        """
        
        # 1. Criar sess√£o (n√£o-t√©cnico + 3 repos)
        response = client.post("/api/sessions", json={
            "user_profile": "non_technical",
            "selected_repositories": [
                "/test/backend-api",
                "/test/frontend-web",
                "/test/mobile-app"
            ]
        })
        session_id = response.json()["session_id"]
        
        # 2. Enviar mensagem que impacta m√∫ltiplos repos
        mock_mcp.return_value.search_code.side_effect = [
            # Backend results
            [{"file": "backend/notifications.py", "score": 0.9}],
            # Frontend results
            [{"file": "frontend/NotificationBell.tsx", "score": 0.85}],
            # Mobile results
            [{"file": "mobile/PushHandler.dart", "score": 0.8}]
        ]
        
        mock_llm.return_value.detect_multi_spec.return_value = {
            "should_split": True,
            "confidence": 0.95,
            "recommended_split": {
                "backend-api": {...},
                "frontend-web": {...},
                "mobile-app": {...}
            }
        }
        
        response = client.post("/api/conversations/message", json={
            "session_id": session_id,
            "message": "Quero notifica√ß√µes push quando m√©dico enviar mensagem"
        })
        
        assert response.status_code == 200
        assert response.json()["multi_spec_detected"] == True
        assert len(response.json()["affected_repositories"]) == 3
        
        # 3. Sistema automaticamente cria 3 conversas
        # ... simular preenchimento das 3 specs
        
        # 4. Exportar (deve gerar 3 arquivos linkados)
        response = client.post("/api/export", json={
            "session_id": session_id,
            "format": "markdown"
        })
        
        specs = response.json()["specs"]
        assert len(specs) == 3
        assert "backend-api" in specs
        assert "frontend-web" in specs
        assert "mobile-app" in specs
        
        # Validar linking entre specs
        backend_md = specs["backend-api"]
        assert "frontend-web" in backend_md
        assert "mobile-app" in backend_md
        assert "Tasks Relacionadas" in backend_md
```

---

## üöÄ PARTE 4: Pr√≥ximas A√ß√µes Recomendadas

### Prioridade CR√çTICA (Antes de `/tasks`)

1. ‚úÖ **Definir Estrat√©gia de Sanitiza√ß√£o** (CR√çTICO)
   - Criar `sanitization-rules.yml`
   - Implementar `SanitizationEngine`
   - Testar com dados reais da empresa

2. ‚úÖ **Formalizar Prompts** (CR√çTICO)
   - Criar `PromptLibrary` com templates
   - Validar prompts com LLM (testes)
   - Documentar expected outputs

3. ‚úÖ **Cat√°logo de Edge Cases** (ALTO)
   - Criar `edge-cases-catalog.yml`
   - Implementar tratamento para top 10
   - Testes de edge cases

### Prioridade ALTA (Durante `/tasks`)

4. ‚úÖ **M√©tricas e Observabilidade**
   - Implementar `MetricsCollector`
   - Dashboard de m√©tricas (/admin/metrics)
   - Alertas para problemas cr√≠ticos

5. ‚úÖ **M√°quina de Estados**
   - Implementar `SessionStateMachine`
   - Validar transi√ß√µes
   - Logging de estados

6. ‚úÖ **Suite de Testes**
   - Testes E2E dos fluxos principais
   - Testes de integra√ß√£o (MCP + LLM)
   - Coverage > 80%

### Prioridade M√âDIA (Durante Implementa√ß√£o)

7. **Otimiza√ß√µes de Performance**
   - Caching de contexto MCP
   - Prompt caching no OpenRouter
   - Rate limiting inteligente

8. **UI Polish**
   - Anima√ß√µes de loading
   - Error states
   - Empty states

9. **Documenta√ß√£o de Usu√°rio**
   - Tutorial interativo
   - FAQ
   - Troubleshooting guide

---

## üìã Checklist de Valida√ß√£o Pr√©-`/tasks`

Antes de executar `/tasks`, validar:

- [x] Especifica√ß√£o completa e aprovada
- [x] Plano t√©cnico detalhado
- [x] Diagramas de arquitetura atualizados
- [x] Fluxos de usu√°rio documentados
- [ ] **Estrat√©gia de sanitiza√ß√£o definida** ‚Üê BLOCKER
- [ ] **Prompts especializados documentados** ‚Üê BLOCKER
- [ ] **Edge cases catalogados** ‚Üê RECOMENDADO
- [x] Stack tecnol√≥gica confirmada
- [x] Integra√ß√µes externas documentadas
- [x] Template de task da empresa dispon√≠vel
- [ ] **M√©tricas de sucesso definidas** ‚Üê RECOMENDADO

---

## üéØ Resumo Executivo

### O que est√° BOM ‚úÖ
- Especifica√ß√£o abrangente e detalhada
- Plano t√©cnico com arquitetura clara
- Diagramas visuais completos
- Features priorit√°rias bem definidas
- Integra√ß√µes documentadas

### O que precisa ATEN√á√ÉO ‚ö†Ô∏è
- **Sanitiza√ß√£o de dados sens√≠veis** - Precisa detalhamento URGENTE
- **Prompts especializados** - Documentar estrutura exata
- **Edge cases** - Catalogar e implementar tratamento
- **M√©tricas** - Definir KPIs espec√≠ficos e coletores

### O que pode ser MELHORADO üí°
- Testes automatizados (expandir cobertura)
- M√°quina de estados (formalizar transi√ß√µes)
- Performance (adicionar benchmarks)
- Documenta√ß√£o de usu√°rio (tutoriais)

---

**Pr√≥ximo Passo Recomendado**: 
1. Definir estrat√©gia de sanitiza√ß√£o (BLOCKER)
2. Documentar prompts especializados (BLOCKER)
3. Executar `/tasks` para quebrar implementa√ß√£o

---

**Criado**: 2025-10-19  
**Status**: An√°lise Completa  
**Vers√£o**: 1.0  
**Reviewers**: TBD

